import argparse
import sys
import time
import cv2
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from picamera2 import Picamera2
from gpiozero import AngularServo
from time import sleep
from utils import visualize

# Initialize the servo on GPIO pin 14
servo = AngularServo(14, min_angle=0, max_angle=180, min_pulse_width=0.5/1000, max_pulse_width=2.5/1000)

# Global variables to calculate FPS
COUNTER, FPS = 0, 0
START_TIME = time.time()
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 480)
picam2.preview_configuration.main.format = "RGB888"
picam2.preview_configuration.align()
picam2.configure("preview")
picam2.start()

# Servo control variables
servo_running = True
angle = 0
direction = 1  # 1 for forward, -1 for reverse

# Function to move servo smoothly
def move_servo():
    global angle, direction, servo_running
    if servo_running:
        angle += 2 * direction
        if angle >= 180:
            direction = -1
        elif angle <= 0:
            direction = 1
        servo.angle = angle
        sleep(0.05)

def run(model: str, max_results: int, score_threshold: float, 
        camera_id: int, width: int, height: int) -> None:
    """Continuously run inference on images acquired from the camera."""

    # Visualization parameters
    row_size = 50  # pixels
    left_margin = 24  # pixels
    text_color = (0, 0, 0)  # black
    warning_color = (0, 0, 255)  # red for warning
    font_size = 1
    font_thickness = 1
    fps_avg_frame_count = 10

    detection_result_list = []

    def save_result(result: vision.ObjectDetectorResult, unused_output_image: mp.Image, timestamp_ms: int):
        global FPS, COUNTER, START_TIME, servo_running

        # Calculate the FPS
        if COUNTER % fps_avg_frame_count == 0:
            FPS = fps_avg_frame_count / (time.time() - START_TIME)
            START_TIME = time.time()

        detection_result_list.append(result)
        COUNTER += 1

    # Initialize the object detection model
    base_options = python.BaseOptions(model_asset_path=model)
    options = vision.ObjectDetectorOptions(base_options=base_options,
                                           running_mode=vision.RunningMode.LIVE_STREAM,
                                           max_results=max_results, score_threshold=score_threshold,
                                           result_callback=save_result)
    detector = vision.ObjectDetector.create_from_options(options)

    while True:
        # Move servo smoothly if it's running
        move_servo()

        # Capture image from camera
        im = picam2.capture_array()
        image = cv2.resize(im, (640, 480))
        image = cv2.flip(image, -1)

        # Convert the image from BGR to RGB as required by the TFLite model
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_image)

        # Run object detection using the model
        detector.detect_async(mp_image, time.time_ns() // 1_000_000)

        # Show FPS
        fps_text = 'FPS = {:.1f}'.format(FPS)
        text_location = (left_margin, row_size)
        current_frame = image
        cv2.putText(current_frame, fps_text, text_location, cv2.FONT_HERSHEY_DUPLEX,
                    font_size, text_color, font_thickness, cv2.LINE_AA)

        # Process detection results
        if detection_result_list:
            result = detection_result_list[0]  # Get the latest result
            for detection in result.detections:
                # Get the bounding box coordinates
                bbox = detection.bounding_box
                x_min = int(bbox.origin_x)
                y_min = int(bbox.origin_y)
                x_max = int(bbox.origin_x + bbox.width)
                y_max = int(bbox.origin_y + bbox.height)

                # Draw the bounding box
                cv2.rectangle(current_frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                # Show the detection confidence score
                score_text = 'Confidence: {:.2f}'.format(detection.categories[0].score)
                cv2.putText(current_frame, score_text, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX,
                            0.6, (255, 255, 255), 2)

                # Check if the detected object is "Fire" and if it's near the center of the frame
                bbox_center_x = (bbox.origin_x + bbox.width / 2) / width
                bbox_center_y = (bbox.origin_y + bbox.height / 2) / height

                # Consider "center" as the middle 20% of the frame
                if 0.4 <= bbox_center_x <= 0.6 and 0.4 <= bbox_center_y <= 0.6:
                    # Stop the servo and show warning
                    servo_running = False
                    cv2.putText(current_frame, "Warning: Fire Detected!", (left_margin, row_size + 50),
                                cv2.FONT_HERSHEY_DUPLEX, font_size, warning_color, font_thickness, cv2.LINE_AA)

            detection_result_list.clear()

        # Show the current frame with detection results
        cv2.imshow('object_detection', current_frame)

        # Stop the program if the ESC key is pressed
        if cv2.waitKey(1) == 27:
            break

    detector.close()
    cv2.destroyAllWindows()

def main():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument(
        '--model',
        help='Path of the object detection model.',
        required=False,
        default='best.tflite')
    parser.add_argument(
        '--maxResults',
        help='Max number of detection results.',
        required=False,
        default=5)
    parser.add_argument(
        '--scoreThreshold',
        help='The score threshold of detection results.',
        required=False,
        type=float,
        default=0.25)
    parser.add_argument(
        '--cameraId', help='Id of camera.', required=False, type=int, default=0)
    parser.add_argument(
        '--frameWidth',
        help='Width of frame to capture from camera.',
        required=False,
        type=int,
        default=640)
    parser.add_argument(
        '--frameHeight',
        help='Height of frame to capture from camera.',
        required=False,
        type=int,
        default=480)
    args = parser.parse_args()

    run(args.model, int(args.maxResults),
        args.scoreThreshold, int(args.cameraId), args.frameWidth, args.frameHeight)


if __name__ == '__main__':
    main()
