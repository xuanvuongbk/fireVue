import time
import cv2
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from picamera2 import Picamera2
from gpiozero import AngularServo
from time import sleep
from utils import visualize

# Initialize the servo on GPIO pin 14
servo = AngularServo(14, min_angle=0, max_angle=180, min_pulse_width=0.5/1000, max_pulse_width=2.5/1000)

# Global variables to calculate FPS
COUNTER, FPS = 0, 0
START_TIME = time.time()
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 480)
picam2.preview_configuration.main.format = "RGB888"
picam2.preview_configuration.align()
picam2.configure("preview")
picam2.start()

# Servo control variables
servo_running = True
angle = 0
direction = 1  # 1 for forward, -1 for reverse

# Function to move servo smoothly
def move_servo():
    global angle, direction, servo_running
    if servo_running:
        angle += 2 * direction
        if angle >= 180:
            direction = -1
        elif angle <= 0:
            direction = 1
        servo.angle = angle
        sleep(0.05)

def run(model: str, max_results: int, score_threshold: float, 
        camera_id: int, width: int, height: int) -> None:
    """Continuously run inference on images acquired from the camera."""

    # Visualization parameters
    row_size = 50  # pixels
    left_margin = 24  # pixels
    text_color = (0, 0, 0)  # black
    warning_color = (0, 0, 255)  # red for warning
    font_size = 1
    font_thickness = 1
    fps_avg_frame_count = 10

    detection_frame = None
    detection_result_list = []

    def save_result(result: vision.ObjectDetectorResult, unused_output_image: mp.Image, timestamp_ms: int):
        global FPS, COUNTER, START_TIME, servo_running

        # Calculate the FPS
        if COUNTER % fps_avg_frame_count == 0:
            FPS = fps_avg_frame_count / (time.time() - START_TIME)
            START_TIME = time.time()

        detection_result_list.append(result)
        COUNTER += 1

    # Initialize the object detection model
    base_options = python.BaseOptions(model_asset_path=model)
    options = vision.ObjectDetectorOptions(base_options=base_options,
                                           running_mode=vision.RunningMode.LIVE_STREAM,
                                           max_results=max_results, score_threshold=score_threshold,
                                           result_callback=save_result)
    detector = vision.ObjectDetector.create_from_options(options)

    while True:
        # Move servo smoothly if it's running
        move_servo()

        # Capture image from camera
        im = picam2.capture_array()
        image = cv2.resize(im, (640, 480))
        image = cv2.flip(image, -1)

        # Convert the image from BGR to RGB as required by the TFLite model
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_image)

        # Run object detection using the model
        detector.detect_async(mp_image, time.time_ns() // 1_000_000)

        # Show FPS
        fps_text = 'FPS = {:.1f}'.format(FPS)
        text_location = (left_margin, row_size)
        current_frame = image
        cv2.putText(current_frame, fps_text, text_location, cv2.FONT_HERSHEY_DUPLEX,
                    font_size, text_color, font_thickness, cv2.LINE_AA)

        # Process detection results
        if detection_result_list:
            result = detection_result_list[0]  # Get the latest result
            for detection in result.detections:
                # Check if the detected object is "Fire" and if it's near the center of the frame
                bbox = detection.bounding_box
                bbox_center_x = (bbox.origin_x + bbox.width / 2) / width
                bbox_center_y = (bbox.origin_y + bbox.height / 2) / height

                # Consider "center" as the middle 20% of the frame
                if 0.4 <= bbox_center_x <= 0.6 and 0.4 <= bbox_center_y <= 0.6:
                    # Trigger warning or action
                    cv2.putText(current_frame, 'Warning: Fire Detected!', (left_margin, row_size * 2),
                                cv2.FONT_HERSHEY_DUPLEX, font_size, warning_color, font_thickness, cv2.LINE_AA)

        # Display the image
        cv2.imshow('Object Detection', current_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    picam2.stop()
    cv2.destroyAllWindows()

# Example usage
run(model='path/to/model.tflite', max_results=5, score_threshold=0.5, camera_id=0, width=640, height=480)
